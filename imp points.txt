What is the worst case time complexity of the following code :
/* 
 * V is sorted 
 * V.size() = N
 * The function is initially called as searchNumOccurrence(V, k, 0, N-1)
 */
int searchNumOccurrence(vector<int> &V, int k, int start, int end) {
    if (start > end) return 0;
    int mid = (start + end) / 2;
    if (V[mid] < k) return searchNumOccurrence(V, k, mid + 1, end);
    if (V[mid] > k) return searchNumOccurrence(V, k, start, mid - 1);
    return searchNumOccurrence(V, k, start, mid - 1) + 1 + searchNumOccurrence(V, k, mid + 1, end);
}
       The algorithm is based on the binary search approach, where at each step, it divides the search space in half.
     If the element at the middle index (mid) is not the target element k, the function is called recursively on the appropriate half of the array, effectively halving the search space in each step.
   However, when the target element is found, the function is called twice more, once to search the left half and once to search the right half, potentially leading to additional recursive calls.
  The worst-case scenario for this algorithm is when the element k is not present in the array. In this case, the function will keep dividing the search space in half until the search space becomes empty. 
  This leads to a linear time complexity, as it effectively touches every element in the array.
Therefore, considering all these points, the worst-case time complexity of the given algorithm is O(N), where N is the size of the vector V.

In the additional recursive calls, when the target element is found, the algorithm attempts to find all occurrences of the element. 
Specifically, the function is called recursively to search the left and right halves of the array from the position where the target element is found. 
This leads to an exploration of both the left and right subarrays, which might contain additional occurrences of the target element.
The additional recursive calls serve to find all occurrences of the element in the array. This contributes to the linear time complexity in the worst case, as every element in the array needs to be examined to count all occurrences.
Overall, these additional recursive calls are essential for counting all occurrences of the target element in the array, which can be scattered across multiple positions within the array.
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Lets look at the code we are evaluating : 
int i, j, k = 0;
    for (i  = n/2; i <= n; i++) {
        for (j = 2; j <= n; j = j * 2) {
            k = k + n/2;
        }
    }
Now, lets just assume `n = 8` for now. 
We will try to see, the values of j corresponding to each i. 
i = 4, j = 2, 4, 8
i = 5, j = 2, 4, 8
i = 6, j = 2, 4, 8
i = 7, j = 2, 4, 8
i = 8, j = 2, 4, 8
if you notice, j keeps doubling till it is less than or equal to n. Number of times, you can double a number till it is less than n would be log(n). 
Lets take more examples here to convince ourselves.
n = 16, j = 2, 4, 8, 16
 n = 32, j = 2, 4, 8, 16, 32
So, j would run for O(log n) steps. 
i runs for n/2 steps. 
So, total steps ` = O (n/ 2 * log (n)) = O(n logn) `
-------------------------------------------------------------------------------------------------------------------------------------------------------------------
gcd of two consecutive fibonacci numbers is one

int gcd(int n, int m) {
  if (n%m ==0) return m;
  if (n < m) swap(n, m);
  while (m > 0) {
    n = n%m;
    swap(n, m);
  }
  return n;
}
What is the time complexity of the above function assuming n > m?. 
Θ symbol represents theta notation and Ω symbol represents omega notation.

The worst case will arise when n and m are consecutive Fibonacci numbers.
i.e. gcd(Fn,Fn−1) = gcd(Fn−1,Fn−2) =⋯ = gcd(F1,F0) = 1
and nth Fibonacci number is 1.618^n, where 1.618 is the Golden ratio.
So, to find gcd(n,m), number of recursive calls will be  Θ(logn).
More detailed explanation : 
Let us say n = fibonacci(N) and m = fibonacci(N - 1)
fibonacci(N) = fibonacci(N-1) + fibonacci(N-2)
OR n = m + k where k and nth Fibonacci number is 1.618n, where 1.618 is the Golden ratio.< m. 
Therefore the step 
    n = n % m will make n = k
    swap(n, m) will result in
    n = fibonacci(N-1)      
    m = k = fibonacci(N-2)
    So, it will take N steps before m becomes 0.
This means, in the worst case, this algorithm can take N step if **n** is Nth fibonacci number. 
**Think of whats the relation between N and n**. 
--------------------------------------------------------------------------------------------------------------------------------------------

 for(i = 0; i < n; i++)---o[N]
 
  for(i = 0; i < n; i += 2)--o[n/2]
 
  for(i = 1; i < n; i *= 2)--o[logn]---best loop

  for(i = n; i > -1; i /= 2)---doesnt terminate
--------------------------------------------------------------------------------------------------------------------------------------------

changed  